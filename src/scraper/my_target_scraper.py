import random
import time
import requests
from fake_useragent import UserAgent
from bs4 import BeautifulSoup
from src.utils.database_handler import DatabaseHandler

class MyTargetScraper:
    def __init__(self, max_workers=1):
        self.base_url = "https://masothue.com/tra-cuu-ma-so-thue-theo-tinh/can-tho-96"
        self.db_handler = DatabaseHandler(db_path="data-grak.db")
        self.user_agent = UserAgent(use_cache_server=False, verify_ssl=False)  # âœ… sá»­a chá»— nÃ y
        self.user_agent = UserAgent(use_cache_server=False, verify_ssl=False, fallback="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 Chrome/115.0.0.0 Safari/537.36")

    def get_random_user_agent(self):
        return self.user_agent.random

    def send_request(self, url):
        headers = {"User-Agent": self.get_random_user_agent()}
        try:
            r = requests.get(url, headers=headers, timeout=10)
            r.raise_for_status()
            return r.text
        except requests.RequestException as e:
            print(f"[REQUEST ERROR] {e}")
            return None

    def parse_company_data(self, page_source):
        soup = BeautifulSoup(page_source, "html.parser")
        company_data = []

        rows = soup.select("table.table-hover.table-bordered tbody tr")
        for row in rows:
            cols = [td.get_text(strip=True) for td in row.find_all("td")]
            if len(cols) < 7:
                continue

            link_elem = row.find("a", href=True)
            detail_link = link_elem["href"] if link_elem else None

            company = {
                "name": cols[1].strip(),
                "tax_id": cols[2].strip(),
                "abbreviation": "",  # KhÃ´ng cÃ³ thÃ¬ Ä‘á»ƒ trá»‘ng
                "address": cols[3].strip(),
                "phone": cols[4].strip(),
                "representative": cols[5].strip(),
                "status": cols[6].strip(),
                "detail_link": detail_link
            }

            # Loáº¡i bá» kÃ½ tá»± khÃ´ng há»£p lá»‡ (náº¿u cÃ³)
            for key in company:
                if isinstance(company[key], str):
                    company[key] = ''.join(c for c in company[key] if c.isprintable())

            company_data.append(company)

        return company_data
    def parse_detail_page(self, link):
        html = self.send_request(link)
        if not html:
            return {}

        soup = BeautifulSoup(html, "html.parser")
        extra_data = {}

        # Láº¥y cÃ¡c trÆ°á»ng thÃ´ng tin tá»« trang chi tiáº¿t
        info_rows = soup.select("div#company-info div.row")
        for row in info_rows:
            label_elem = row.find("label")
            value_elem = row.find("div", class_="col-md-8")
            if label_elem and value_elem:
                label = label_elem.get_text(strip=True)
                value = value_elem.get_text(strip=True)
                extra_data[label] = value

        return extra_data





    def save_to_db(self, companies):
        for c in companies:
            self.db_handler.insert_company(c)

    def start(self):
        all_companies = []
        seen_tax_ids = set()
        page = 1

        while True:
            url = f"{self.base_url}?page={page}" if page > 1 else self.base_url
            print(f"â³ Äang cÃ o page {page} â€¦")
            html = self.send_request(url)
            if not html:
                print("KhÃ´ng thá»ƒ truy cáº­p hoáº·c háº¿t page.")
                break

            batch = self.parse_company_data(html)
            if not batch:
                print("â€“ KhÃ´ng tÃ¬m tháº¥y DN trÃªn page nÃ y, dá»«ng.")
                break

            new_batch = [c for c in batch if c["tax_id"] not in seen_tax_ids]
            if not new_batch:
                print("â€“ ToÃ n bá»™ DN Ä‘Ã£ cÃ o trÆ°á»›c Ä‘Ã³, dá»«ng pagination.")
                break

            for company in new_batch:
                if company["detail_link"]:
                    detail_data = self.parse_detail_page(company["detail_link"])
                    company.update(detail_data)

            print(f"â†’ Page {page}: tÃ¬m Ä‘Æ°á»£c {len(batch)} DN, trong Ä‘Ã³ {len(new_batch)} DN má»›i.")
            all_companies.extend(new_batch)
            seen_tax_ids.update(c["tax_id"] for c in new_batch)

            page += 1
            time.sleep(random.uniform(1, 2))

        if all_companies:
            print(f"\nğŸ‰ Tá»•ng cá»™ng cÃ o Ä‘Æ°á»£c {len(all_companies)} DN má»›i. Äang lÆ°u vÃ o DBâ€¦")
            self.save_to_db(all_companies)
            print(f"âœ… ÄÃ£ lÆ°u {len(all_companies)} DN vÃ o database.")
        else:
            print("âš ï¸ KhÃ´ng tÃ¬m tháº¥y DN nÃ o má»›i.")
            
        self.db_handler.close()
